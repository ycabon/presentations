// All material copyright ESRI, All Rights Reserved, unless otherwise specified.
// See https://js.arcgis.com/4.8/esri/copyright.txt for details.
//>>built
require({cache:{"url:esri/views/2d/engine/webgl/shaders/hlShaders.xml":'\x3c?xml version\x3d"1.0" encoding\x3d"UTF-8"?\x3e\n\x3c!--\n  Highlight generation and rendering shaders.\n\n  These shader sources are loaded by hlShaderSnippets.ts which in turn\n  is used by HighlightRenderer to instantiate the programs needed for\n  generating and rendering the highlights.\n\n  These shaders are intended to be used with full screen quads.\n--\x3e\n\x3csnippets\x3e\n  \x3c!--\n    Vertex shader: texturedVS\n\n    Identity vertex shader that outputs an untransformed 2-D vertex\n    and passes its texture coordinates unchanged to the interpolator.\n  --\x3e\n  \x3csnippet name\x3d"texturedVS"\x3e\n    \x3c![CDATA[\n    // Vertex position.\n    attribute mediump vec2 a_position;\n\n    // Texture coordinates.\n    attribute mediump vec2 a_texcoord;\n\n    // Texture coordinates to be interpolated.\n    varying mediump vec2 v_texcoord;\n\n    void main(void) {\n      // Pass the position unchanged.\n      gl_Position \x3d vec4(a_position, 0.0, 1.0);\n\n      // Pass the texture coordinates unchanged.\n      v_texcoord \x3d a_texcoord;\n    }\n    ]]\x3e\n  \x3c/snippet\x3e\n\n  \x3c!--\n    Fragment shader: blurFS\n\n    A gaussian blur shader. It blurs the alpha channel of its input\n    according to 4 different sigma and stores the results into the\n    four channel of the target framebuffer.\n\n    It is intended to be called twice; the first time to perform an\n    horizontal blur, and a second time to perform a vertical blur.\n\n    This shader is used to turn the highlight mask into a highlight\n    map. The highlight map is an approximation of the signed distance\n    field of the mask.\n  --\x3e\n  \x3csnippet name\x3d"blurFS"\x3e\n    \x3c![CDATA[\n    // Interpolated texture coordinates.\n    varying mediump vec2 v_texcoord;\n\n    // Blur direction information. There are two possible\n    // configurations that the host code can use.\n    //  - [1, 0, 1/WIDTH, 0] Used when blurring horizontally. In this\n    //    case u_direction[0] \x3d 1 is expressed in pixel and is fed to\n    //    the gauss function to produce the value of the gaussian weight\n    //    for that pixel, while u_direction[2] \x3d 1/WIDTH is in texel units\n    //    and is used to sample the right texel from the texture map.\n    //  - [0, 1, 0, 1/HEIGHT] Used when blurring vertically. In this\n    //    case u_direction[1] \x3d 1 is expressed in pixel and is fed to\n    //    the gauss function to produce the value of the gaussian weight\n    //    for that pixel, while u_direction[3] \x3d 1/HEIGHT is in texel units\n    //    and is used to sample the right texel from the texture map.\n    uniform mediump vec4 u_direction;\n\n    // Source to destination channel selection matrix.\n    uniform mediump mat4 u_channelSelector;\n\n    // The highlight map is obtained by blurring the alpha channel of the highlight\n    // mask accroding to these 4 values of the gaussian\'s sigma parameter.\n    uniform mediump vec4 u_sigmas;\n\n    // This is the highlight mask if we have not blurred horizontally yet, otherwise\n    // it is the horizontally blurred highlight map and blurring it one more time\n    // vertically will complete the process.\n    uniform sampler2D u_texture;\n\n    // The gaussian kernel. Note that it lacks the normalization constant, because\n    // we want to store it unnormalized in the highlight map (i.e. having a peak\n    // value of 1). Note also that we are using the SIMD (single instruction, multiple\n    // data) capabilities of the GPU to compute four different gaussian kernels, one\n    // for each sigma.\n    mediump vec4 gauss(mediump vec2 dir) {\n      return exp(-dot(dir, dir) / (2.0 * u_sigmas * u_sigmas));\n    }\n\n    mediump vec4 selectChannel(mediump vec4 sample) {\n      return u_channelSelector * sample;\n    }\n\n    // Sample the input texture and accumulated its gaussian weighted value and the\n    // total weight.\n    void accumGauss(mediump float i, inout mediump vec4 tot, inout mediump vec4 weight) {\n      // Computes the gaussian weights, one for each sigma.\n      // Note that u_direction.xy is [1, 0] when blurring horizontally and [0, 1] when blurring vertically.\n      mediump vec4 w \x3d gauss(i * u_direction.xy);\n\n      // Accumumates the values.\n      // Note that u_direction.xy is [1/WIDTH, 0] when blurring horizontally and [0, 1/HEIGHT] when blurring vertically.\n      tot +\x3d selectChannel(texture2D(u_texture, v_texcoord + i * u_direction.zw)) * w;\n\n      // Accumulates the weights.\n      weight +\x3d w;\n    }\n\n    void main(void) {\n      // Initialize accumulated values and weights to zero.\n      mediump vec4 tot \x3d vec4(0.0, 0.0, 0.0, 0.0);\n      mediump vec4 weight \x3d vec4(0.0, 0.0, 0.0, 0.0);\n\n      // Accumulates enough samples. These will be taken\n      // horizontally or vertically depending on the value\n      // of u_direction.\n      accumGauss(-5.0, tot, weight);\n      accumGauss(-4.0, tot, weight);\n      accumGauss(-3.0, tot, weight);\n      accumGauss(-2.0, tot, weight);\n      accumGauss(-1.0, tot, weight);\n      accumGauss(0.0, tot, weight);\n      accumGauss(1.0, tot, weight);\n      accumGauss(2.0, tot, weight);\n      accumGauss(3.0, tot, weight);\n      accumGauss(4.0, tot, weight);\n      accumGauss(5.0, tot, weight);\n\n      // Compute blurred values.\n      mediump vec4 rgba \x3d tot / weight;\n\n      // Return the values. Note that each channel will contain\n      // the result of a different blur operation, one for each\n      // of the four chosen sigma.\n      gl_FragColor \x3d vec4(rgba);\n    }\n    ]]\x3e\n  \x3c/snippet\x3e\n\n  \x3c!--\n    Fragment shader: highlightFS\n\n    Takes as input the highlight map, estimated the signed distance field,\n    and shades the fragments according to their estimated distance from the\n    edge of the highlighted feature.\n\n    A shade texture is used to turn distance values into colors; the shade\n    texture is basically a color gradient and is recomputed on the host\n    every time that the user alters the highlight options.\n  --\x3e\n  \x3csnippet name\x3d"highlightFS"\x3e\n    \x3c![CDATA[\n    // Interpolated texture coordinates.\n    varying mediump vec2 v_texcoord;\n\n    // The highlight map. Each channel is a blurred\n    // version of the alpha channel of the highlight mask.\n    //  - Channel 0 (red) corresponds to a gaussian blur with sigma \x3d u_sigmas[0];\n    //  - Channel 1 (green) corresponds to a gaussian blur with sigma \x3d u_sigmas[1];\n    //  - Channel 2 (blue) corresponds to a gaussian blur with sigma \x3d u_sigmas[2];\n    //  - Channel 3 (alpha) corresponds to a gaussian blur with sigma \x3d u_sigmas[3];\n    // As of today, only channel 3 is used for distance estimation.\n    // But the availability of different amounts of blur leaves the\n    // door open to multi-scale approaches.\n    uniform sampler2D u_texture;\n\n    // The highlight map was obtained by blurring the alpha channel of the highlight\n    // mask accroding to these 4 values of the gaussian\'s sigma parameter.\n    uniform mediump vec4 u_sigmas;\n\n    // A 1-D texture used to shade the highlight.\n    uniform sampler2D u_shade;\n\n    // The 1-D shade texture is spreaded between u_minMaxDistance[0] and u_minMaxDistance[1].\n    uniform mediump vec2 u_minMaxDistance;\n\n    // Signed distance estimation.\n    mediump float estimateDistance() {\n      // Use the largest sigma and the corresponding distance value stored in the\n      // last channel of the highlight map.\n      mediump float sigma \x3d u_sigmas[3];\n      mediump float y \x3d texture2D(u_texture, v_texcoord)[3];\n\n      // Estimates the distance by linearization and local inversion around\n      // the inflection point. The inflection point is in x \x3d 0.\n      const mediump float y0 \x3d 0.5;                           // Value of the convolution at the inflection point.\n      mediump float m0 \x3d 1.0 / (sqrt(2.0 * 3.1415) * sigma);  // Slope of the convolution at the inflection point.\n      mediump float d \x3d (y - y0) / m0;                        // Inversion of a local linearization.\n\n      // Return the estimated distance.\n      return d;\n    }\n\n    // Shading based on estimated distance.\n    mediump vec4 shade(mediump float d) {\n      // Maps the sampled distance from the [A, D] range (see HighlightRenderer::setHighlightOptions) to [0, 1].\n      mediump float mappedDistance \x3d (d - u_minMaxDistance.x) / (u_minMaxDistance.y - u_minMaxDistance.x);\n\n      // Force to [0, 1]; it should not be necessary because the shade texture uses the CLAMP address mode, so\n      // this should happen anyway internally to the sampler, but in practice it is needed to avoid weird\n      // banding artifacts.\n      // We don\'t really know if we need this or not.\n      mappedDistance \x3d clamp(mappedDistance, 0.0, 1.0);\n\n      // Sample the 1-D shade texture on its center line (i.e. on t\x3d0.5).\n      return texture2D(u_shade, vec2(mappedDistance, 0.5));\n    }\n\n    void main(void) {\n      // Estimate the distance.\n      mediump float d \x3d estimateDistance();\n\n      // Shade the distance.\n      gl_FragColor \x3d shade(d);\n    }\n    ]]\x3e\n  \x3c/snippet\x3e\n\x3c/snippets\x3e\n'}});
define(["require","exports","dojo/text!./hlShaders.xml","../../../../webgl/ShaderSnippets"],function(a,d,c,b){a=new b;b.parse(c,a);return a});