// All material copyright ESRI, All Rights Reserved, unless otherwise specified.
// See https://js.arcgis.com/4.8/esri/copyright.txt for details.
//>>built
require({cache:{"url:esri/views/3d/webgl-engine/materials/LineCalloutMaterial.xml":'\x3c?xml version\x3d"1.0" encoding\x3d"UTF-8"?\x3e\n\n\x3csnippets\x3e\n\n\x3csnippet name\x3d"vertexShaderLineCallout"\x3e\x3c![CDATA[\n  $vsprecisionf\n\n  $commonAttributesAndUniformsHUD\n\n  attribute vec2 $uv0;\n\n  uniform float lineSize;\n  uniform vec2 pixelToNDC;\n  uniform float borderSize;\n  uniform vec2 screenOffset;\n\n  varying vec4 coverageSampling;\n  varying vec2 lineSizes;\n\n  $alignToPixelOrigin\n  $alignToPixelCenter\n\n  $projectPositionHUD\n\n  void main(void) {\n    ProjectHUDAux projectAux;\n    vec4 endPoint \x3d projectPositionHUD(projectAux);\n\n#ifdef OCCL_TEST\n    if (!testVisibilityHUD(endPoint)) {\n      gl_Position \x3d vec4(1e38, 1e38, 1e38, 1);\n    }\n    else {\n#endif\n\n#ifdef SCREEN_SIZE_PERSPECTIVE\n      vec4 perspectiveFactor \x3d screenSizePerspectiveScaleFactor(projectAux.absCosAngle, projectAux.distanceToCamera, screenSizePerspectiveAlignment);\n      vec2 screenOffsetScaled \x3d applyScreenSizePerspectiveScaleFactorVec2(screenOffset, perspectiveFactor);\n#else\n      vec2 screenOffsetScaled \x3d screenOffset;\n#endif\n\n      // Add view dependent polygon offset to get exact same original starting point. This is mostly\n      // used to get the correct depth value\n      vec3 posView \x3d (view * model * vec4($position, 1.0)).xyz;\n      applyHUDViewDependentPolygonOffset($auxpos1.w, projectAux.absCosAngle, posView);\n\n      vec4 startPoint \x3d proj * vec4(posView, 1);\n\n      // Apply screen offset to both start and end point\n      vec2 screenOffsetNorm \x3d screenOffsetScaled * 2.0 / viewport.zw;\n\n      startPoint.xy +\x3d screenOffsetNorm * startPoint.w;\n      endPoint.xy +\x3d screenOffsetNorm * endPoint.w;\n\n      // Align start and end to pixel origin\n      vec4 startAligned \x3d alignToPixelOrigin(startPoint, viewport.zw);\n      vec4 endAligned \x3d alignToPixelOrigin(endPoint, viewport.zw);\n\n#ifdef DEPTH_HUD\n\n#ifdef DEPTH_HUD_ALIGN_START\n      endAligned \x3d vec4(endAligned.xy / endAligned.w * startAligned.w, startAligned.zw);\n#else\n      startAligned \x3d vec4(startAligned.xy / startAligned.w * endAligned.w, endAligned.zw);\n#endif\n\n#endif\n\n      vec4 projectedPosition \x3d mix(startAligned, endAligned, $uv0.y);\n\n      // The direction of the line in screen space\n      vec2 screenSpaceDirection \x3d normalize(endAligned.xy / endAligned.w - startAligned.xy / startAligned.w);\n      vec2 perpendicularScreenSpaceDirection \x3d vec2(screenSpaceDirection.y, -screenSpaceDirection.x);\n\n#ifdef SCREEN_SIZE_PERSPECTIVE\n\n      float lineSizeScaled \x3d applyScreenSizePerspectiveScaleFactorFloat(lineSize, perspectiveFactor);\n      float borderSizeScaled \x3d applyScreenSizePerspectiveScaleFactorFloat(borderSize, perspectiveFactor);\n\n#else\n\n      float lineSizeScaled \x3d lineSize;\n      float borderSizeScaled \x3d borderSize;\n\n#endif\n\n      float halfPixelSize \x3d lineSizeScaled * 0.5;\n\n      // Calculate a pixel offset from the edge of the pixel, s.t. we keep the line aligned\n      // to pixels if it has a full pixel size. Since pixel aligned biases to the bottom-left,\n      // we bias the size to the right (for odd sizes) to balance out the bias. Grow sub-pixel\n      // sizes towards the left or right s.t. there is a smooth transition (e.g. from 2 to 3 px).\n      float halfWholePixelSize \x3d floor(lineSizeScaled) * 0.5;\n      float halfPixelSizeInt \x3d floor(halfWholePixelSize);\n\n      // Sub-pixel offset if we need to grow sub-pixels to the left\n      float subpixelOffset \x3d -fract(lineSizeScaled) * float(halfWholePixelSize \x3e 0.0);\n\n      // Pixel offset aligning to whole pixels and adding subpixel offset if needed\n      float pixelOffset \x3d -halfPixelSizeInt + subpixelOffset;\n\n      // Compute full ndc offset, adding 1px padding for doing anti-aliasing and the border size\n      float padding \x3d 1.0 + borderSizeScaled;\n      vec2 ndcOffset \x3d (pixelOffset - padding + $uv0.x * (lineSizeScaled + padding + padding)) * pixelToNDC;\n\n      // Offset x/y from the center of the line in screen space\n      projectedPosition.xy +\x3d perpendicularScreenSpaceDirection * ndcOffset * projectedPosition.w;\n\n      // Compute a coverage varying which we can use in the fragment shader to determine\n      // how much a pixel is actually covered by the line (i.e. to anti alias the line).\n      // This works by computing two coordinates that can be linearly interpolated and then\n      // subtracted to find out how far away from the line edge we are.\n      float edgeDirection \x3d ($uv0.x * 2.0 - 1.0);\n\n      float halfBorderSize \x3d 0.5 * borderSizeScaled;\n      float halfPixelSizeAndBorder \x3d halfPixelSize + halfBorderSize;\n      float outerEdgeCoverageSampler \x3d edgeDirection * (halfPixelSizeAndBorder + halfBorderSize + 1.0);\n\n      float isOneSided \x3d float(lineSizeScaled \x3c 2.0 \x26\x26 borderSize \x3c 2.0);\n\n      coverageSampling \x3d vec4(\n        // Edge coordinate\n        outerEdgeCoverageSampler,\n\n        // Border edge coordinate\n        outerEdgeCoverageSampler - halfPixelSizeAndBorder * isOneSided,\n\n        // Line offset\n        halfPixelSize - 0.5,\n\n        // Border offset\n        halfBorderSize - 0.5 + halfPixelSizeAndBorder * (1.0 - isOneSided)\n      );\n\n      lineSizes \x3d vec2(lineSizeScaled, borderSizeScaled);\n\n      gl_Position \x3d projectedPosition;\n\n#ifdef OCCL_TEST\n    }\n#endif\n  }\n]]\x3e\x3c/snippet\x3e\n\n\x3csnippet\x3e\x3c![CDATA[\n\n]]\x3e\x3c/snippet\x3e\n\n\x3csnippet name\x3d"fragmentShaderLineCallout"\x3e\x3c![CDATA[\n  $fsprecisionf\n\n  uniform vec4 color;\n  uniform vec4 borderColor;\n\n  varying vec4 coverageSampling;\n  varying vec2 lineSizes;\n\n  void main() {\n    // Mix between line and border coverage offsets depending on whether we need\n    // a border (based on the sidedness).\n    vec2 coverage \x3d min(1.0 - clamp(abs(coverageSampling.xy) - coverageSampling.zw, 0.0, 1.0), lineSizes);\n\n    // Mix between border and line color based on the line coverage (conceptually the line\n    // blends on top of the border background).\n    //\n    // Anti-alias by blending final result using the full (including optional border) coverage\n    // and the color alpha\n    float borderAlpha \x3d color.a * borderColor.a * coverage.y;\n    float colorAlpha \x3d color.a * coverage.x;\n\n    float finalAlpha \x3d mix(borderAlpha, 1.0, colorAlpha);\n\n#ifdef DEPTH_HUD\n\n    if (finalAlpha \x3c 0.01) {\n      discard;\n    }\n\n#else\n\n    // Compute the finalRgb, but keep it pre-multiplied (for unpre-multiplied you\n    // need to divide by finalAlpha). We avoid the division here by setting the\n    // appropriate blending function in the material.\n    vec3 finalRgb \x3d mix(borderColor.rgb * borderAlpha, color.rgb, colorAlpha);\n\n    gl_FragColor \x3d vec4(finalRgb, finalAlpha);\n\n#endif\n\n  }\n]]\x3e\x3c/snippet\x3e\n\n\x3c/snippets\x3e\n'}});
define("require exports ../../../../core/tsSupport/extendsHelper dojo/text!./LineCalloutMaterial.xml ../lib/GLMaterial ../lib/Material ../lib/RenderSlot ../lib/ShaderVariations ../lib/Util ./internal/MaterialUtil ../../../webgl/Util".split(" "),function(m,C,n,t,u,v,p,w,x,f,q){function r(d,b,a){3===a.length?d.setUniform4f(b,a[0],a[1],a[2],1):d.setUniform4fv(b,a)}var g=x.VertexAttrConstants,k=[{name:"position",count:3,type:5126,offset:0,stride:48,normalized:!1},{name:"normal",count:3,type:5126,offset:12,
stride:48,normalized:!1},{name:"uv0",count:2,type:5126,offset:24,stride:48,normalized:!1},{name:"auxpos1",count:4,type:5126,offset:32,stride:48,normalized:!1}],y={verticalOffset:null,screenSizePerspective:null,screenOffset:[0,0],color:[0,0,0,1],size:1,borderColor:null,occlusionTest:!1,shaderPolygonOffset:1E-5,depthHUDAlignStart:!1,centerOffsetUnits:"world"};m=function(d){function b(a,c){c=d.call(this,c)||this;c.params=f.copyParameters(a,y);c._uniqueMaterialIdentifier=b.uniqueMaterialIdentifier(c.params);
return c}n(b,d);Object.defineProperty(b.prototype,"uniqueMaterialIdentifier",{get:function(){return this._uniqueMaterialIdentifier},enumerable:!0,configurable:!0});b.prototype.dispose=function(){};b.prototype.getGLMaterials=function(){return{color:z,depthShadowMap:void 0,normal:void 0,depth:void 0,highlight:void 0}};b.prototype.getAllTextureIds=function(){return[]};b.prototype.fillAttributeData=function(a,c,b,e,h,d){var l=a.indices[c];a=a.vertexAttr[c].data;if(l&&a)for(c=b+q.findAttribute(k,c).offset/
4,b=0;b<l.length;b++)for(var A=e*l[b],g=0;6>g;g++)f.fill(a,A,d,c,h,e),c+=12};b.prototype.fillInterleaved=function(a,c,b,e,h,d,f){this.fillAttributeData(a,g.POSITION,d,3,c,h);this.fillAttributeData(a,g.NORMAL,d,3,b,h);this.fillAttributeData(a,g.AUXPOS1,d,4,null,h);a=d+q.findAttribute(k,g.UV0).offset/4;c=0;for(b=B;c<b.length;c++)e=b[c],h[a+0]=e[0],h[a+1]=e[1],a+=12};b.prototype.getOutputAmount=function(a){return 288*a};b.prototype.getInstanceBufferLayout=function(){};b.prototype.getVertexBufferLayout=
function(){return k};b.prototype.intersect=function(a,c,b,e,d,f,g,k){};b.prototype.getParameterValues=function(){var a=this.params;return{verticalOffset:a.verticalOffset,screenSizePerspective:a.screenSizePerspective,screenOffset:a.screenOffset,centerOffsetUnits:a.centerOffsetUnits,color:[a.color[0],a.color[1],a.color[2],a.color[3]],size:a.size,borderColor:a.borderColor,occlusionTest:a.occlusionTest,shaderPolygonOffset:a.shaderPolygonOffset,depthHUDAlignStart:a.depthHUDAlignStart}};b.prototype.setParameterValues=
function(a){f.updateParameters(this.params,a)&&(this._uniqueMaterialIdentifier=b.uniqueMaterialIdentifier(this.params),this.notifyDirty("matChanged"))};b.uniqueMaterialIdentifier=function(a){return JSON.stringify({screenOffset:a.screenOffset||[0,0],centerOffsetUnits:a.centerOffsetUnits||"world"})};b.loadShaders=function(a,c,b){a._parse(t);a=new w("lineCallout",["vertexShaderLineCallout","fragmentShaderLineCallout"],null,c,a,b);a.addDefine("occlTest","OCCL_TEST");a.addDefine("verticalOffset","VERTICAL_OFFSET");
a.addDefine("screenSizePerspective","SCREEN_SIZE_PERSPECTIVE");a.addDefine("depthHud","DEPTH_HUD");a.addDefine("depthHudAlignStart","DEPTH_HUD_ALIGN_START");a.addDefine("centerOffsetUnitsScreen","CENTER_OFFSET_UNITS_SCREEN");c.addShaderVariations("line-callout-material-shader-variations",a)};return b}(v);var z=function(d){function b(a,c,b){a=d.call(this,a,c)||this;a.isRenderSlot=!0;a.updateParameters();return a}n(b,d);b.prototype.updateParameters=function(){this.params=this.material.getParameterValues();
this.selectProgram()};b.prototype.selectProgram=function(){var a=this.params;this.renderProgram=this.programRep.getShaderVariationsProgram("line-callout-material-shader-variations",[!!a.occlusionTest,!!a.verticalOffset,!!a.screenSizePerspective,!1,!!a.depthHUDAlignStart,"screen"===a.centerOffsetUnits]);this.depthProgram=this.programRep.getShaderVariationsProgram("line-callout-material-shader-variations",[!!a.occlusionTest,!!a.verticalOffset,!!a.screenSizePerspective,!0,!!a.depthHUDAlignStart,"screen"===
a.centerOffsetUnits])};b.prototype.beginSlot=function(a){switch(a){case p.LINE_CALLOUTS:return this.isRenderSlot=!0;case p.LINE_CALLOUTS_HUD_DEPTH:return this.isRenderSlot=!1,!0}return!1};Object.defineProperty(b.prototype,"program",{get:function(){return this.isRenderSlot?this.renderProgram:this.depthProgram},enumerable:!0,configurable:!0});b.prototype.getProgram=function(){return this.program};b.prototype.getPrograms=function(){return[this.renderProgram,this.depthProgram]};b.prototype.getDrawMode=
function(a){return a.gl.TRIANGLES};b.prototype.bind=function(a,c){var b=c.cameraAboveGround?1:-1,e=this.program,d=this.params;a.bindProgram(e);e.setUniform1f("cameraGroundRelative",b);e.setUniform1f("polygonOffset",d.shaderPolygonOffset);e.setUniform4fv("viewport",c.viewport);e.setUniformMatrix4fv("viewNormal",c.viewInvTransp);e.setUniform1i("hudVisibilityTexture",0);a.bindTexture(c.hudVisibilityTexture,0);r(e,"color",d.color);e.setUniform2f("screenOffset",d.screenOffset[0],d.screenOffset[1]);this.bindBorder(a,
c);f.bindVerticalOffset(d.verticalOffset,c,e);this.bindSizing(a,c);f.bindScreenSizePerspective(d.screenSizePerspective,e);this.isRenderSlot?this.bindRender(a,c):this.bindHUDDepth(a,c)};b.prototype.bindRender=function(a,b){a.setBlendFunctionSeparate(1,771,770,771);a.setBlendingEnabled(!0);a.setDepthWriteEnabled(!1)};b.prototype.bindHUDDepth=function(a,b){a.setColorMask(!1,!1,!1,!1);a.setDepthWriteEnabled(!0);a.setBlendingEnabled(!1);a.setDepthTestEnabled(!0)};b.prototype.bindView=function(a,b){a=this.program;
f.bindView(b.origin,b.view,a);f.bindCamPos(b.origin,b.viewInvTransp,a)};b.prototype.bindInstance=function(a,b){a=this.program;a.setUniformMatrix4fv("model",b.transformation);a.setUniformMatrix4fv("modelNormal",b.transformationNormal)};b.prototype.release=function(a,b){this.isRenderSlot?this.releaseRender(a,b):this.releaseHUDDepth(a,b)};b.prototype.releaseRender=function(a,b){a.setBlendingEnabled(!1);a.setBlendFunction(770,771);a.setDepthWriteEnabled(!0)};b.prototype.releaseHUDDepth=function(a,b){a.setColorMask(!0,
!0,!0,!0)};b.prototype.bindSizing=function(a,b){a=this.program;var c=this.params;a.setUniform2f("pixelToNDC",2/b.viewport[2],2/b.viewport[3]);a.setUniform1f("lineSize",Math.ceil(c.size))};b.prototype.bindBorder=function(a,b){a=this.program;b=this.params;null!==b.borderColor?(r(a,"borderColor",b.borderColor),a.setUniform1f("borderSize",1)):(a.setUniform4f("borderColor",0,0,0,0),a.setUniform1f("borderSize",0))};return b}(u),B=[[0,0],[1,0],[0,1],[1,0],[1,1],[0,1]];return m});